{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30b0d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers, losses\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a880e3",
   "metadata": {},
   "source": [
    "# Data location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "592d0ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In data: ['formulas.txt', 'names.txt', 'test', 'train']\n",
      "In train: ['formula', 'formulas-90%.txt', 'name', 'names-90%.txt']\n",
      "In test: ['formula', 'formulas-10%.txt', 'name', 'names-10%.txt']\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"organic-formula-name\"\n",
    "\n",
    "dataset_directory = os.path.join(os.path.dirname(\"data\"), \"data\", data_folder)\n",
    "train_directory = os.path.join(dataset_directory, \"train\")\n",
    "test_directory = os.path.join(dataset_directory, \"test\")\n",
    "\n",
    "print(\"In data:\", os.listdir(dataset_directory))\n",
    "print(\"In train:\", os.listdir(train_directory))\n",
    "print(\"In test:\", os.listdir(test_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee3cb6",
   "metadata": {},
   "source": [
    "### Sample file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a82a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CH(NO2)(Cl)-O-CHI-CH2-CH2-CH2-CH3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_file = os.path.join(train_directory, \"formula\", \"aa.txt\")\n",
    "\n",
    "print(open(sample_file).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756c0db",
   "metadata": {},
   "source": [
    "# Data collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4386e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 32 # Random seed for data shuffling and transformations\n",
    "validation_split = 0.2 # Proportion of train data used to validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecc4ea5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 471862 files belonging to 2 classes.\n",
      "Using 377490 files for training.\n"
     ]
    }
   ],
   "source": [
    "raw_train_data_source = tf.keras.utils.text_dataset_from_directory(\n",
    "    train_directory,\n",
    "    subset = \"training\",\n",
    "    seed = seed,\n",
    "    validation_split = validation_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f060c1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 471862 files belonging to 2 classes.\n",
      "Using 94372 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_validation_data_source = tf.keras.utils.text_dataset_from_directory(\n",
    "    train_directory,\n",
    "    subset = \"validation\",\n",
    "    seed = seed,\n",
    "    validation_split = validation_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75fa3fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52429 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_test_data_source = tf.keras.utils.text_dataset_from_directory(\n",
    "    test_directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa595445",
   "metadata": {},
   "source": [
    "# Data pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de24885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_standardization(input_data): # CH3-CH=CH-CH(NO2)Br\n",
    "    input_data = tf.strings.lower(input_data) # ch3-ch=ch-ch(no2)br\n",
    "    input_data = tf.strings.regex_replace(input_data, \"[^a-zà-ú]\", ' ') # ch  ch ch ch no  br\n",
    "    return tf.strings.regex_replace(input_data, \"\\s+\", ' ') # ch ch ch ch no br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c743ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 2048 # Sets a boundary for len(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5ad8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 16 # Vectorized string's dimension\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    output_mode = \"int\",\n",
    "    max_tokens = max_features,\n",
    "    standardize = data_standardization,\n",
    "    output_sequence_length = sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "960154cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pablo\\PycharmProjects\\quimify-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Makes a text-only dataset (without labels), then calls adapt\u001B[39;00m\n\u001B[0;32m      2\u001B[0m train_text \u001B[38;5;241m=\u001B[39m raw_train_data_source\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x, y: x)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mvectorize_layer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madapt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_text\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\quimify-classifier\\venv\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py:472\u001B[0m, in \u001B[0;36mTextVectorization.adapt\u001B[1;34m(self, data, batch_size, steps)\u001B[0m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21madapt\u001B[39m(\u001B[38;5;28mself\u001B[39m, data, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    423\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Computes a vocabulary of string terms from tokens in a dataset.\u001B[39;00m\n\u001B[0;32m    424\u001B[0m \n\u001B[0;32m    425\u001B[0m \u001B[38;5;124;03m    Calling `adapt()` on a `TextVectorization` layer is an alternative to\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;124;03m          argument is not supported with array inputs.\u001B[39;00m\n\u001B[0;32m    471\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 472\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madapt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\quimify-classifier\\venv\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:258\u001B[0m, in \u001B[0;36mPreprocessingLayer.adapt\u001B[1;34m(self, data, batch_size, steps)\u001B[0m\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n\u001B[0;32m    257\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n\u001B[1;32m--> 258\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_adapt_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    259\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m    260\u001B[0m             context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\PycharmProjects\\quimify-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\PycharmProjects\\quimify-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\PycharmProjects\\quimify-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    917\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 919\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[0;32m    921\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    922\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\quimify-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    132\u001B[0m   (concrete_function,\n\u001B[0;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\quimify-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1748\u001B[0m     args,\n\u001B[0;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1750\u001B[0m     executing_eagerly)\n\u001B[0;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\PycharmProjects\\quimify-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\PycharmProjects\\quimify-classifier\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Makes a text-only dataset (without labels), then calls adapt\n",
    "train_text = raw_train_data_source.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return vectorize_layer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073a5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrieves a batch of 32 reviews and labels from the dataset\n",
    "text_batch, label_batch = next(iter(raw_train_data_source))\n",
    "first_review, first_label = text_batch[0], label_batch[0]\n",
    "\n",
    "print(\"Review:\", first_review)\n",
    "print(\"Label:\", raw_train_data_source.class_names[first_label])\n",
    "print(\"Vectorized review:\", vectorize_text(first_review, first_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253bb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vocabulary size:\", len(vectorize_layer.get_vocabulary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e400c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vocabulary:\", sorted(vectorize_layer.get_vocabulary(), key = len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_source = raw_train_data_source.map(vectorize_text)\n",
    "validation_data_source = raw_validation_data_source.map(vectorize_text)\n",
    "test_data_source = raw_test_data_source.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5efbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE # ??\n",
    "\n",
    "train_data_source = train_data_source.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "validation_data_source = validation_data_source.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "test_data_source = test_data_source.cache().prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ef8355",
   "metadata": {},
   "source": [
    "# Model creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d817ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16 # ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  layers.Embedding(max_features + 1, embedding_dim),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(256, activation = \"relu\"),\n",
    "  layers.GlobalAveragePooling1D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bf238e",
   "metadata": {},
   "source": [
    "### Loss function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dce3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    metrics = tf.metrics.BinaryAccuracy(threshold = 0.0),\n",
    "    loss = losses.BinaryCrossentropy(from_logits = True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c305297",
   "metadata": {},
   "source": [
    "### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d28708",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "history = model.fit(\n",
    "    epochs = epochs,\n",
    "    x = train_data_source,\n",
    "    validation_data = validation_data_source,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892bb372",
   "metadata": {},
   "source": [
    "### Compiling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a0ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model = tf.keras.Sequential([\n",
    "  vectorize_layer,\n",
    "  model,\n",
    "  layers.Activation(\"sigmoid\")\n",
    "])\n",
    "\n",
    "export_model.compile(\n",
    "    optimizer = \"adam\", \n",
    "    metrics = [\"accuracy\"],\n",
    "    loss = losses.BinaryCrossentropy(from_logits = False), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305bb10",
   "metadata": {},
   "source": [
    "# Model evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e11c5",
   "metadata": {},
   "source": [
    "### Using test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f31b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_data_source)\n",
    "\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f52fc7",
   "metadata": {},
   "source": [
    "### Using raw test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = export_model.evaluate(raw_test_data_source)\n",
    "\n",
    "print(\"Raw test loss:\", loss)\n",
    "print(\"Raw test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6abe3d6",
   "metadata": {},
   "source": [
    "### Accuracy graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae66db",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "accuracy = history_dict[\"binary_accuracy\"]\n",
    "validation_accuracy = history_dict[\"val_binary_accuracy\"]\n",
    "loss = history_dict[\"loss\"]\n",
    "validation_loss = history_dict[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.plot(epochs, accuracy, \"bo\", label = \"Training accuracy\") # Blue dots\n",
    "plt.plot(epochs, validation_accuracy, \"b\", label = \"Validation accuracy\") # Blue line\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe64ce",
   "metadata": {},
   "source": [
    "### Loss graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b11d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, loss, \"ro\", label = \"Training loss\") # Red dots\n",
    "plt.plot(epochs, validation_loss, \"r\", label = \"Validation loss\") # Red line\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f99029",
   "metadata": {},
   "source": [
    "# Model predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cd9675",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"H3C-CH2\",\n",
    "    \"ChCh\",\n",
    "    \"CH3-CO-O-CH2-CH3\",\n",
    "    \"CH3-CH2-O-CH2-CH3\",\n",
    "    \"CH3-CH2-CH=CH-COOH\",\n",
    "    \"ch3chch2ch(ch2ch2ch3)cooh\",\n",
    "    \"ch3(Ch3)Chch2Ch(Ch3)Ch2Ch(Ch2Ch2Ch3)Ch3\",\n",
    "    \"benceno\",\n",
    "    \"2-cloropentanato\",\n",
    "    \"di 2-cloropentanil éter\",\n",
    "    \"2-bromo-2-cloropropano\",\n",
    "    \"metanoato de isopropilo\",\n",
    "    \"orto-difenilciclohexano\",\n",
    "    \"2-bromo-2-cloropropil yododecil éter\",\n",
    "    \"3-cloro-2-fluoro-hexa-1,3-dien-5-in-1-ona\",\n",
    "    \"4-amino-2,6,6-tricloro-7,7-difluoro-89-metil-3-nitro-1,1-diyodononaconta-1,3-dien-5-ona\",\n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    percentage = export_model.predict([example])[0][0] * 100\n",
    "    print(\"Formula\" if percentage < 50 else \"Name\", \"(\" + \"%.2f\" % percentage + \" %):\", example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
